{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3e384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 10:58:14.806094: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-24 10:58:14.860593: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-24 10:58:16.229420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4eaf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Internet is a global phenomenon that plays a pivotal role in the daily lives of billions of people. Originally developed as ARPANET (Advanced Research Projects Agency Network), the internet's primary goal was to\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the Hugging Face summarization pipeline using the flan-T5 model.\n",
    "summarizer = pipeline(\"summarization\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# Define the text to be summarized.\n",
    "text = \"\"\"\n",
    "    The internet, a revolutionary technology that began in the late 1960s as a project \n",
    "    of the United States Department of Defense, has transformed into a global phenomenon \n",
    "    that plays a pivotal role in the daily lives of billions of people. \n",
    "    Originally developed as ARPANET (Advanced Research Projects Agency Network), \n",
    "    the internet's primary goal was to enable computer networks to communicate with each other, \n",
    "    especially in the event of a nuclear attack.\n",
    "\"\"\"\n",
    "\n",
    "# Generate a summary of the provided text.\n",
    "summary = summarizer(text, max_length=50)\n",
    "\n",
    "# Print the summarized text.\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc13111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'nothate', 'score': 4.664432048797607}, {'label': 'hate', 'score': -4.196918964385986}]\n",
      "[{'label': 'hate', 'score': 0.37227317690849304}, {'label': 'nothate', 'score': -0.6921192407608032}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment analysis pipeline using a RoBERTa model specifically trained for detecting hate speech. non-hate speech categories.\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n",
    "\n",
    "# Two example texts for analysis.\n",
    "non_hate_text = \"I love using new technology tools for my projects!\"\n",
    "hate_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
    "\n",
    "# Parameters for retrieving raw logits from the model.\n",
    "# 'top_k': None - Returns scores for all classes.\n",
    "# 'function_to_apply': 'none' - Retrieves raw logits without applying any transformation like softmax.\n",
    "# 'batch_size': 16 - Processes up to 16 texts in a batch for faster computation.\n",
    "reward_logits_kwargs = {\n",
    "    \"top_k\": None,\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "# Analyze the texts and print the raw logits.\n",
    "print(sentiment_analyzer(non_hate_text, **reward_logits_kwargs))\n",
    "print(sentiment_analyzer(hate_text, **reward_logits_kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8038ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Hugging, Entity: I-ORG\n",
      "Word: Face, Entity: I-ORG\n",
      "Word: Inc, Entity: I-ORG\n",
      "Word: New, Entity: I-LOC\n",
      "Word: York, Entity: I-LOC\n",
      "Word: City, Entity: I-LOC\n",
      "Word: Transformer, Entity: I-MISC\n",
      "Word: Google, Entity: I-ORG\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize a Named Entity Recognition (NER) pipeline using the BERT model fine-tuned on CoNLL-03 English data.\n",
    "# This model is optimized for identifying named entities (like person names, locations, organizations) in English text.\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "\n",
    "# Example text for NER. The model will identify named entities in this text.\n",
    "text = \"\"\"\n",
    "    Hugging Face Inc. is a company based in New York City. \n",
    "    Its technology is based on a Transformer model developed by researchers at Google.\n",
    "\"\"\"\n",
    "\n",
    "# Perform Named Entity Recognition on the text.\n",
    "# The output will be a list of entities with details like the word, entity type, and confidence score.\n",
    "ner_results = ner_pipeline(text)\n",
    "\n",
    "# Function to reconstruct full words from subword tokens and associate them with their respective entity type.\n",
    "# BERT and similar models often break down words into smaller sub-units (subwords), which this function will recombine.\n",
    "def reconstruct_words_from_tokens(ner_results):\n",
    "    reconstructed_words = []\n",
    "    current_word = \"\"\n",
    "    current_entity = \"\"\n",
    "\n",
    "    for item in ner_results:\n",
    "        token = item['word']\n",
    "        entity = item['entity']\n",
    "\n",
    "        # Check if the token is a continuation of the previous word (subwords in BERT start with '##').\n",
    "        if token.startswith(\"##\"):\n",
    "            current_word += token[2:]  # Remove the '##' and append to the current word.\n",
    "        else:\n",
    "            # If the token is a new word, store the previous word and its entity type, then start a new word.\n",
    "            if current_word:\n",
    "                reconstructed_words.append((current_word, current_entity))\n",
    "            current_word = token\n",
    "            current_entity = entity\n",
    "\n",
    "    # Add the last accumulated word if it exists.\n",
    "    if current_word:\n",
    "        reconstructed_words.append((current_word, current_entity))\n",
    "\n",
    "    return reconstructed_words\n",
    "\n",
    "# Use the helper function to get the full words and their entities.\n",
    "reconstructed_words = reconstruct_words_from_tokens(ner_results)\n",
    "\n",
    "# Print each word along with its identified entity type.\n",
    "for word, entity in reconstructed_words:\n",
    "    print(f\"Word: {word}, Entity: {entity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3438b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize a question-answering pipeline using the DistilBERT model.\n",
    "qa_pipeline = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "# Define the context and the question.\n",
    "# Context: A passage or text where the answer to the question can be found.\n",
    "# Question: The question we want to find an answer to from the context.\n",
    "context = \"Hugging Face is a technology company based in New York. It specializes in Natural Language Processing.\"\n",
    "question = \"What does Hugging Face specialize in?\"\n",
    "\n",
    "# Use the pipeline to find the answer to the question based on the context.\n",
    "answer = qa_pipeline(question=question, context=context)\n",
    "\n",
    "# Print the answer.\n",
    "print(answer['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16cc8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a distant future, humans and AI coexist in harmony. Humanity's only chance to fight a powerful corporation is to harness technology and engineering to create an alternate universe, and it may be even earlier.\n",
      "\n",
      "The story, titled: Humanity vs\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the text generation pipeline using the GPT-2 model.\n",
    "text_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Define the prompt for text generation.\n",
    "prompt = \"In a distant future, humans and AI coexist in harmony.\"\n",
    "\n",
    "# Generate text based on the prompt.\n",
    "generated_text = text_generator(prompt, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# Print the generated text.\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0f186cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face ist ein hervorragendes Werkzeug für die Verarbeitung natürlicher Sprachen.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# Initialize the tokenizer for the T5 model with a specified maximum length.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\", model_max_length=512)\n",
    "\n",
    "# Initialize the translation pipeline.\n",
    "translator = pipeline(\"translation_en_to_de\", model=\"t5-base\", tokenizer=tokenizer)\n",
    "\n",
    "# Example text that we want to translate from English to German.\n",
    "text_to_translate = \"Hugging Face is a great tool for Natural Language Processing.\"\n",
    "\n",
    "# Perform the translation.\n",
    "translated_text = translator(text_to_translate, max_length=40)\n",
    "\n",
    "# Print the translated text.\n",
    "print(translated_text[0]['translation_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c6ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NNP)",
   "language": "python",
   "name": "nnp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
